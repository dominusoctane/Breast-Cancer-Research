{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7396db0-7823-43e9-bd97-f462a15de485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link 'resnet.py': File exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 17:35:34.507112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "# Required imports\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "import seaborn as sns\n",
    "\n",
    "# Enable matplotlib inline mode for Jupyter Notebook\n",
    "%matplotlib inline\n",
    "        \n",
    "# Constants\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "IMAGE_EXT = '.jpg'\n",
    "BASE_PATH = '/workspace/0728tot/last_experiment/'\n",
    "RESIZE_DIMS = (224, 224)\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "\n",
    "!ln -s /workspace/0728tot/last_experiment/resnet.py resnet.py\n",
    "from resnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14d3c6a4-0752-4884-896e-0a80c71aa126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory paths\n",
    "\n",
    "# Folders containing original DUV WSI\n",
    "ORIGINAL_IMAGES_DIR = os.path.join(BASE_PATH, 'unknown_DUV_WSI')\n",
    "\n",
    "# Folder containing reshaped DUV WSI\n",
    "RESHAPED_IMAGES_DIR = os.path.join(BASE_PATH, 'reshaped_unknown_DUV_WSI')\n",
    "\n",
    "# Folders processing the GradCAM++ results\n",
    "RAW_MAP_DIR = os.path.join(BASE_PATH, 'unknown_DenseNet169ImageNetGradCAM_2')\n",
    "FINAL_HEAT_MAP_DIR = os.path.join(BASE_PATH, 'unknown_DenseNet169ImageNetGradCAM')\n",
    "FINAL_OVERLAY_HEAT_MAP_DIR = os.path.join(BASE_PATH, 'unknown_DUV_finalheatmap/')\n",
    "\n",
    "# Folders for holding the GradCAM++ results and patch level results in a grid system\n",
    "GRADCAM_GRID_MAP_DIR = os.path.join(BASE_PATH, 'unknown_gradcam_gridmap')\n",
    "PRED_GRID_MAP_DIR = os.path.join(BASE_PATH, 'unknown_patch_gridmap')\n",
    "\n",
    "# Folders for processing the patch level and GradCAM++ results for visualization purposes\n",
    "PROCESS_PATCHES_DIR = os.path.join(BASE_PATH,'unknown_process_patchmaps')\n",
    "BOUNDING_BOXES_OVERLAY_DIR = os.path.join(BASE_PATH,'unknown_bounding_boxes_overlays')\n",
    "\n",
    "# Folders for patch related info\n",
    "PATCH_DIR = os.path.join(BASE_PATH, 'unknown_Patches')\n",
    "PATCH_FEATURES_DIR = os.path.join(BASE_PATH, 'unknown_Patches_features')\n",
    "PRIOR_PATCH_FEATURES_DIR = os.path.join(BASE_PATH, 'DUV_features')\n",
    "PRIOR_PATCH_DATA_CSV = os.path.join(BASE_PATH, 'duvdata.csv')\n",
    "\n",
    "# Folder for getting training splits, an example\n",
    "SPLIT_DIR = os.path.join(BASE_PATH, 'prior_train_splits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fe88c21-e377-4832-9e93-d83a2c30c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all new patch and prediction directories exist\n",
    "all_directories = [RAW_MAP_DIR, FINAL_HEAT_MAP_DIR, GRADCAM_GRID_MAP_DIR, PRED_GRID_MAP_DIR, PATCH_DIR, PATCH_FEATURES_DIR]\n",
    "for directory in all_directories:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "# Helper functions\n",
    "def create_dataframe(data_folder, is_map_format=False):\n",
    "    '''Creates a dataframe for the dataset. \n",
    "       If is_map_format is True, it uses the logic specific to map format.'''\n",
    "    data_entries = []\n",
    "    for root, _, files in os.walk(data_folder):\n",
    "        for filename in files:\n",
    "            relative_path = os.path.relpath(root, data_folder)\n",
    "            file_extension = os.path.splitext(filename)[-1]\n",
    "            if file_extension == '.jpg':\n",
    "                try:\n",
    "                    if is_map_format:\n",
    "                        name_parts = filename.replace(\".\", \"_\").split('_')\n",
    "                        subject, side, _ = name_parts\n",
    "                    else:\n",
    "                        name_parts = filename.split('_')\n",
    "                        subject = int(name_parts[0].split('.')[0])\n",
    "                        side = int(name_parts[1].split('.')[0]) if len(name_parts) > 1 else 0\n",
    "                    full_path = os.path.join(root, filename)\n",
    "                    entry = {\n",
    "                        'relative_path': relative_path, \n",
    "                        'filename': filename, \n",
    "                        'subject': subject, \n",
    "                        'side': side, \n",
    "                        'full_path': full_path\n",
    "                    }\n",
    "                    data_entries.append(entry)\n",
    "                except:\n",
    "                    pass\n",
    "    data_frame = pd.DataFrame(data_entries)\n",
    "    return data_frame\n",
    "\n",
    "def save_foreground_image(image_path, output_directory, subject_id, side_id):\n",
    "    image = cv2.imread(image_path)\n",
    "    grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    denoised_image = cv2.fastNlMeansDenoising(grayscale_image, None, 25, 7, 21)\n",
    "    edges_image = cv2.Canny(denoised_image, 100, 100, L2gradient=True)\n",
    "    x, y, w, h = cv2.boundingRect(edges_image)\n",
    "    foreground_image = image[y:y+h, x:x+w]\n",
    "    output_path = os.path.join(output_directory, f\"{subject_id}_{side_id}.jpg\")\n",
    "    cv2.imwrite(output_path, foreground_image)\n",
    "\n",
    "def compute_foreground_ratio(image):\n",
    "    background_threshold = 5\n",
    "    return np.mean(image[:, :, 1] >= background_threshold)\n",
    "\n",
    "dataset_frame = create_dataframe(ORIGINAL_IMAGES_DIR)\n",
    "dataset_frame = dataset_frame.sort_values('subject')\n",
    "image_paths = dataset_frame.full_path.to_numpy()\n",
    "subject_ids = dataset_frame.subject.to_list()\n",
    "side_ids = dataset_frame.side.to_list()\n",
    "\n",
    "# Getting the recropped images to reduce processing time\n",
    "for index in range(len(dataset_frame)):\n",
    "    save_foreground_image(image_paths[index], RESHAPED_IMAGES_DIR, subject_ids[index], side_ids[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aa05567-394f-4894-b3b2-ceacc1a37e83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.811657905578613\n",
      "17.011672973632812\n",
      "19.407439947128296\n",
      "21.95302677154541\n",
      "24.92561936378479\n",
      "29.61857557296753\n",
      "39.890738010406494\n",
      "48.88908624649048\n",
      "54.881184101104736\n",
      "61.17561435699463\n",
      "63.11239051818848\n",
      "65.61716294288635\n",
      "70.35196781158447\n",
      "74.57070779800415\n",
      "77.53427457809448\n",
      "79.96434259414673\n",
      "82.26051473617554\n",
      "84.26114797592163\n",
      "88.1029806137085\n",
      "90.83645367622375\n",
      "92.14929461479187\n",
      "93.40744519233704\n",
      "96.88540887832642\n",
      "100.29750967025757\n",
      "106.00837278366089\n",
      "111.89108872413635\n",
      "117.11548328399658\n",
      "123.82678627967834\n",
      "135.56371593475342\n",
      "141.87888503074646\n",
      "142.6039924621582\n",
      "143.4754159450531\n",
      "144.8688383102417\n",
      "148.20301127433777\n",
      "151.0614960193634\n",
      "154.23908162117004\n",
      "156.50515747070312\n",
      "159.10237216949463\n",
      "159.90557098388672\n",
      "161.298588514328\n",
      "163.14071822166443\n",
      "166.92461562156677\n",
      "182.45984768867493\n",
      "183.28068232536316\n",
      "185.19795322418213\n",
      "188.99002265930176\n",
      "189.32873558998108\n",
      "190.72538447380066\n",
      "193.1427035331726\n",
      "195.5515193939209\n",
      "200.62160873413086\n",
      "205.38245820999146\n",
      "207.2925591468811\n",
      "209.41530466079712\n",
      "211.18473362922668\n",
      "215.37937712669373\n",
      "217.89483046531677\n",
      "220.83547282218933\n",
      "221.92537927627563\n",
      "223.1334080696106\n",
      "224.2692632675171\n",
      "225.6667263507843\n",
      "228.22118735313416\n",
      "230.41386198997498\n",
      "235.6295485496521\n",
      "240.7889850139618\n",
      "243.16083455085754\n",
      "246.4247281551361\n",
      "248.11133551597595\n",
      "250.52811908721924\n",
      "252.07990527153015\n",
      "254.28672170639038\n",
      "257.27965259552\n",
      "259.61512303352356\n",
      "267.40514373779297\n",
      "270.5875895023346\n",
      "273.2075848579407\n",
      "277.19371342658997\n",
      "282.76111912727356\n",
      "285.56319522857666\n",
      "288.0856420993805\n"
     ]
    }
   ],
   "source": [
    "# Patch Extraction\n",
    "subject_side_pairs = [f\"{subj}_{side}\" for subj, side in zip(subject_ids, side_ids)]\n",
    "for pair in subject_side_pairs:\n",
    "    full_patch_directory = os.path.join(PATCH_DIR, f'S{pair}')\n",
    "    shutil.rmtree(full_patch_directory, ignore_errors=True)\n",
    "    os.makedirs(full_patch_directory)\n",
    "\n",
    "processed_frame = create_dataframe(RESHAPED_IMAGES_DIR, is_map_format=True)\n",
    "processed_frame = processed_frame.sort_values(by=['subject'], ignore_index=True)\n",
    "processed_image_paths = processed_frame.full_path.to_list()\n",
    "final_subject_ids = processed_frame.subject.to_numpy()\n",
    "final_side_ids = processed_frame.side.to_numpy()\n",
    "\n",
    "patch_width, patch_height = 400, 400\n",
    "start_time = time.time()\n",
    "\n",
    "for idx, image_path in enumerate(processed_image_paths):\n",
    "    image = cv2.imread(image_path)\n",
    "    image_height, image_width = image.shape[:2]\n",
    "    resized_width, resized_height = (math.ceil(dim/400) * 400 for dim in (image_width, image_height))\n",
    "    resized_image = cv2.resize(image, (resized_width, resized_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    for x in range(0, resized_width - patch_width + 1, patch_width):\n",
    "        for y in range(0, resized_height - patch_height + 1, patch_height):\n",
    "            cropped_image = resized_image[y:y+patch_height, x:x+patch_width]\n",
    "            if compute_foreground_ratio(cropped_image) > 0.8:\n",
    "                filename = os.path.join(PATCH_DIR, f'S{final_subject_ids[idx]}_{final_side_ids[idx]}', f'{idx}_{x//patch_width}-{y//patch_height}.png')\n",
    "                cv2.imwrite(filename, cropped_image)\n",
    "    print(time.time() - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
